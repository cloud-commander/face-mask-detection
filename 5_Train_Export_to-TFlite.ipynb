{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "4_Train_Model.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEZrJutQ8DuV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<a href=\"https://blog.cloudcommander.net\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/cloud-commander/hexoblog/master/cloud.png\" alt=\"Visit my Blog\">\n",
        "</a>\n",
        "<br> \n",
        "# <span style=\"font-family:Didot; font-size:3em;\"> Cloud Commander </span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olMsSiKF8DuW",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloud-commander/face-mask-detection/blob/master/5_Train_Export_to-TFlite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"></a>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<a href=\"https://github.com/cloud-commander/face-mask-detection/blob/master/5_Train_Export_to-TFlite.ipynb\" target=\"_parent\"><img src=\"https://img.shields.io/static/v1?logo=GitHub&label=&color=333333&style=flat&message=View%20on%20GitHub\" alt=\"View in GitHub\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG4FfhYT8DuX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# Tensorflow Lite Conversion #\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/128/1*cKG1LJvVTaWqSkYSyVqtsQ.png\"  alt=\"Visit my Blog\"> \n",
        "\n",
        "<img src=\"https://lh3.googleusercontent.com/vvBAqSnXyg3h9yS0JLyVehhV-e__3NFbZ6q7Ft-rEZp-9wDTVZ49yjuYJwfa4jQZ-RVnChHMr-DDC0T_fTxVyQg3iBMD-icMQooD6A=w630-rw\" alt=\"Visit my Blog\">\n",
        "\n",
        "Once we have our trained model, there is one final step we must take before we are ready to start testing the model. \n",
        "\n",
        "We have to convert the frozen graph into a TF Lite model which our inference application can use. The model is quantized, which means it is compatible with Edge TPU devices such as Google Coral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmzWtRC8DuX",
        "colab_type": "text"
      },
      "source": [
        "### Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVVgHA7c7b4_",
        "colab_type": "code",
        "outputId": "47ae1a0a-a323-4eda-8efc-a1844357c81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "!sudo apt-get update\n",
        "\n",
        "!sudo apt-get install edgetpu-compiler\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   653  100   653    0     0  15547      0 --:--:-- --:--:-- --:--:-- 15547\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [856 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [933 kB]\n",
            "Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,831 kB]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [883 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,387 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,230 kB]\n",
            "Get:20 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\n",
            "Get:22 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [1,270 B]\n",
            "Ign:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [162 kB]\n",
            "Fetched 7,621 kB in 1s (5,282 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libedgetpu1-std\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler libedgetpu1-std\n",
            "0 upgraded, 2 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 4,998 kB of archives.\n",
            "After this operation, 18.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 libedgetpu1-std amd64 14.0 [306 kB]\n",
            "Get:2 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 14.0 [4,692 kB]\n",
            "Fetched 4,998 kB in 1s (8,129 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libedgetpu1-std:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libedgetpu1-std_14.0_amd64.deb ...\n",
            "Unpacking libedgetpu1-std:amd64 (14.0) ...\n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "Preparing to unpack .../edgetpu-compiler_14.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (14.0) ...\n",
            "Setting up libedgetpu1-std:amd64 (14.0) ...\n",
            "Setting up edgetpu-compiler (14.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rMllIVy-etr",
        "colab_type": "text"
      },
      "source": [
        "### Prepare dataset ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiecZysJ-khD",
        "colab_type": "text"
      },
      "source": [
        "#### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ownRZYo_-eLG",
        "colab_type": "code",
        "outputId": "38a44f16-3fbd-45c0-ef28-43ae48f0c5ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKsmrGMv-rS6",
        "colab_type": "text"
      },
      "source": [
        "#### Copy dataset from Google Drive and extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53jAn5YD-rH0",
        "colab_type": "code",
        "outputId": "d27ee26c-3ea2-4ab8-b4ea-ee449c51ff36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Datasets/\n",
        "%cp model_graph.zip /content/\n",
        "%cd /content/\n",
        "!unzip -o /content/model_graph.zip\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Datasets\n",
            "/\n",
            "Archive:  /content/model_graph.zip\n",
            "   creating: trained_inference_graphs/\n",
            "  inflating: trained_inference_graphs/checkpoint  \n",
            "  inflating: trained_inference_graphs/pipeline.config  \n",
            "  inflating: trained_inference_graphs/model.ckpt.meta  \n",
            "  inflating: trained_inference_graphs/model.ckpt.data-00000-of-00001  \n",
            "   creating: trained_inference_graphs/saved_model/\n",
            "   creating: trained_inference_graphs/saved_model/variables/\n",
            "  inflating: trained_inference_graphs/saved_model/saved_model.pb  \n",
            "  inflating: trained_inference_graphs/model.ckpt.index  \n",
            "  inflating: trained_inference_graphs/frozen_inference_graph.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ-pt4_sY-kF",
        "colab_type": "code",
        "outputId": "27356a86-7659-4875-b798-1a91ed885309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%cd /content/\n",
        "!unzip -o /content/model_graph.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Archive:  /content/model_graph.zip\n",
            "   creating: trained_inference_graphs/\n",
            "  inflating: trained_inference_graphs/checkpoint  \n",
            "  inflating: trained_inference_graphs/pipeline.config  \n",
            "  inflating: trained_inference_graphs/model.ckpt.meta  \n",
            "  inflating: trained_inference_graphs/model.ckpt.data-00000-of-00001  \n",
            "   creating: trained_inference_graphs/saved_model/\n",
            "   creating: trained_inference_graphs/saved_model/variables/\n",
            "  inflating: trained_inference_graphs/saved_model/saved_model.pb  \n",
            "  inflating: trained_inference_graphs/model.ckpt.index  \n",
            "  inflating: trained_inference_graphs/frozen_inference_graph.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od3jjP2NzAWs",
        "colab_type": "code",
        "outputId": "150b3d1a-f2f6-46b3-8ebd-62a96e98c68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!tflite_convert \\\n",
        "! --output_file=\"/content/output_tflite_graph.tflite\" \\\n",
        "! --graph_def_file=\"/content/trained_inference_graphs/frozen_inference_graph.pb\" \\\n",
        "! --input_arrays='input' \\\n",
        "! --output_arrays='TFLite_Detection_PostProcess' \\\n",
        "! --inference_type=QUANTIZED_UINT8 \\\n",
        "! --mean_values=128 \\\n",
        "! --std_dev_values=128 \\\n",
        "! --input_shapes=1,300,300,3 \\\n",
        "! --change_concat_input_ranges=false \\\n",
        "! --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n",
        "! --allow_custom_ops"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-09 16:30:12.775293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-09 16:30:12.777095: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-06-09 16:30:12.777140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b2ec1e9bfca0): /proc/driver/nvidia/version does not exist\n",
            "2020-06-09 16:30:12.777502: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-06-09 16:30:12.783186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2020-06-09 16:30:12.783450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1894a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-09 16:30:12.783486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.6/bin/tflite_convert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n",
            "    app.run(main=run_main, argv=sys.argv[:1])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n",
            "    _convert_tf1_model(tflite_flags)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 124, in _convert_tf1_model\n",
            "    converter = _get_toco_converter(flags)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 111, in _get_toco_converter\n",
            "    return converter_fn(**converter_kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/lite.py\", line 705, in from_frozen_graph\n",
            "    sess.graph, input_arrays)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/util.py\", line 122, in get_tensors_from_tensor_names\n",
            "    \",\".join(invalid_tensors)))\n",
            "ValueError: Invalid tensors 'input' were found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19aTPPZFgfls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DqazGvph3wi",
        "colab_type": "text"
      },
      "source": [
        "## Save "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X12bFD9Ih90j",
        "colab_type": "text"
      },
      "source": [
        "### Archive the inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh7Laulzh9ci",
        "colab_type": "code",
        "outputId": "6e462706-9388-41ac-f41e-35821f5655ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_demo\n",
            "--2020-06-05 08:59:06--  https://raw.githubusercontent.com/cloud-commander/face-mask-detection/master/data/ssd_mobilenet_v2_coco.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4766 (4.7K) [text/plain]\n",
            "Saving to: ‘ssd_mobilenet_v2_coco.config’\n",
            "\n",
            "ssd_mobilenet_v2_co 100%[===================>]   4.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-05 08:59:06 (46.5 MB/s) - ‘ssd_mobilenet_v2_coco.config’ saved [4766/4766]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8b-JYPviFty",
        "colab_type": "text"
      },
      "source": [
        "### Save archive to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H2ZbZ0eiKMD",
        "colab_type": "code",
        "outputId": "aaf75f71-17d5-4d85-fcc6-0ebba85d8c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training_demo/images/test\n",
            "185\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}