{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "5_Train_Export_to_TF_Lite.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEZrJutQ8DuV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<a href=\"https://blog.cloudcommander.net\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/cloud-commander/hexoblog/master/cloud.png\" alt=\"Visit my Blog\">\n",
        "</a>\n",
        "<br> \n",
        "# <span style=\"font-family:Didot; font-size:3em;\"> Cloud Commander </span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olMsSiKF8DuW",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloud-commander/face-mask-detection/blob/master/5_Train_Export_to_TF_Lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"></a>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<a href=\"https://github.com/cloud-commander/face-mask-detection/blob/master/5_Train_Export_to_TF_Lite.ipynb\" target=\"_parent\"><img src=\"https://img.shields.io/static/v1?logo=GitHub&label=&color=333333&style=flat&message=View%20on%20GitHub\" alt=\"View in GitHub\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG4FfhYT8DuX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# TensorFlow Lite Conversion #\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*AO4WEkrSRz4Xb7qzkbqcvg.png\"  alt=\"Visit my Blog\"> \n",
        "\n",
        "<img src=\"https://lh3.googleusercontent.com/vvBAqSnXyg3h9yS0JLyVehhV-e__3NFbZ6q7Ft-rEZp-9wDTVZ49yjuYJwfa4jQZ-RVnChHMr-DDC0T_fTxVyQg3iBMD-icMQooD6A=w630-rw\" alt=\"Visit my Blog\">\n",
        "\n",
        "Once we have our trained model, there is one final step we must take before we are ready to start testing the model. \n",
        "\n",
        "We have to convert the frozen graph into a TF Lite model which our inference application can use. The model is quantized, which means it is compatible with Edge TPU devices such as Google Coral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M7dEvcXy3DI",
        "colab_type": "text"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiecZysJ-khD",
        "colab_type": "text"
      },
      "source": [
        "### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ownRZYo_-eLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmzWtRC8DuX",
        "colab_type": "text"
      },
      "source": [
        "## Install required libraries\n",
        "Be sure to click on the **restart** button after running this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsd9FASzFwAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U --pre tensorflow==\"1.*\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4AnozPNzJrP",
        "colab_type": "text"
      },
      "source": [
        "Make sure you have `pycocotools` installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rMllIVy-etr",
        "colab_type": "text"
      },
      "source": [
        "# Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZYR0SROEzfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/cloud-commander/face-mask-detection/master/config/constants.py\n",
        "from constants import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfbz28yYRMVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd {DRIVE_DEV}\n",
        "%cp part5-tflite-modelv9.zip /content/\n",
        "%cd /\n",
        "!unzip -o /content/part5-tflite-modelv9.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o42Hn1gPRBs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(TF_LITE_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "def representative_dataset_gen():\n",
        "  for _ in range(num_calibration_steps):\n",
        "    # Get sample input data as a numpy array in a method of your choosing.\n",
        "    yield [input]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "tflite_quant_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}