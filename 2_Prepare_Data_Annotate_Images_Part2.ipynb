{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "1_Prepare_Data_Annotate_Images_Part2.ipynb",
      "provenance": []
    }
  },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"https://blog.cloudcommander.net\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/cloud-commander/hexoblog/master/cloud.png\" alt=\"Visit my Blog\"></a> <span style=\"font-family:Didot; font-size:3em;\"> Cloud Commander </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/cloud-commander/face-mask-detection/blob/master/2_Prepare_Data_Annotate_Images_Part2.ipynb" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"></a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"https://github.com/cloud-commander/face-mask-detection/blob/master/2_Prepare_Data_Annotate_Images_Part2.ipynb" target=\"_parent\"><img src=\"https://img.shields.io/static/v1?logo=GitHub&label=&color=333333&style=flat&message=View%20on%20GitHub\" alt=\"View in GitHub\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Face Image Annotation & Masked Photo Generation ##\n",
    "\n",
    "In the previous notebook, we prepared the unmasked photos in the dataset. In this notebook we will look at pre-processing the images for our masked photo dataset.\n",
    "\n",
    "Firstly we will identify the bounding boxes for the faces as with the unmasked photos but additionally we will then also place a series of masked into those faces thus making them masked photos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (4.5.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.18.1)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.7/site-packages (3.17.2)\n",
      "Requirement already satisfied: dlib in /opt/conda/lib/python3.7/site-packages (19.19.0)\n",
      "Requirement already satisfied: face_recognition in /opt/conda/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from face_recognition) (7.1.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from face_recognition) (7.1.1)\n",
      "Requirement already satisfied: dlib>=19.7 in /opt/conda/lib/python3.7/site-packages (from face_recognition) (19.19.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from face_recognition) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "!pip install opencv-python\n",
    "!pip install cmake\n",
    "!pip install dlib\n",
    "!pip install face_recognition\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "import random\n",
    "import face_recognition\n",
    "\n",
    "from lxml import etree as ET\n",
    "from PIL import Image, ImageFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set image directory ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/masked\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download required dependency (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/cloud-commander/face-mask-detection/master/utils/lbpcascade_frontalface_improved.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Generate_Data/dataset/masked-labels\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "filename = path + \"/\" + dataset_dir\n",
    "face_cascade = cv2.CascadeClassifier('lbpcascade_frontalface_improved.xml')\n",
    "dataset_labels_folder = dataset_dir + \"-labels\"\n",
    "dataset_labels_path = os.getcwd()+ \"/\"+ dataset_labels_folder \n",
    "print(dataset_labels_path)\n",
    "os.mkdir(dataset_labels_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(filename):\n",
    "    for file in files:\n",
    "\n",
    "        \n",
    "        img_path=os.path.join(subdir, file)\n",
    "        img_name=os.path.basename(img_path)\n",
    "\n",
    "        if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            h,w,bpp = np.shape(img)\n",
    "            imgp = Image.open(img_path)\n",
    "#            b, landmarks = detect_faces(imgp)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "#            g=show_bboxes(imgp, b, landmarks)\n",
    "            #print(len(faces))\n",
    "            if len(faces) == 1 :\n",
    "                try :\n",
    "\n",
    "                    for bounding_boxes in faces:\n",
    "                        face = img[int(bounding_boxes[1]):int(bounding_boxes[3]),\n",
    "                        int(bounding_boxes[0]):int(bounding_boxes[2])]\n",
    "\n",
    "                        \n",
    "                        subdir_path, subdir_name = os.path.split(subdir)\n",
    "\n",
    "                        root = ET.Element(\"annotation\",verified=\"yes\")\n",
    "                        ET.SubElement(root, \"folder\").text=filename\n",
    "\n",
    "                        ET.SubElement(root, \"filename\").text = img_name\n",
    "                        ET.SubElement(root, \"path\").text = img_path\n",
    "\n",
    "                        source=ET.SubElement(root, \"source\")\n",
    "                        ET.SubElement(source, \"database\").text = \"unknown\"\n",
    "\n",
    "                        size=ET.SubElement(root, \"size\")\n",
    "                        ET.SubElement(size, \"width\").text = str(w)\n",
    "                        ET.SubElement(size, \"height\").text = str(h)\n",
    "                        ET.SubElement(size, \"depth\").text = str(bpp)\n",
    "\n",
    "                        ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "\n",
    "                        obj=ET.SubElement(root, \"object\")\n",
    "                        ET.SubElement(obj, \"name\").text = subdir_name\n",
    "                        ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
    "                        ET.SubElement(obj, \"truncated\").text = \"0\"\n",
    "                        ET.SubElement(obj, \"difficult\").text = \"0\"\n",
    "\n",
    "                        box=ET.SubElement(obj, \"bndbox\")\n",
    "                        ET.SubElement(box, \"xmin\").text = str(int(bounding_boxes[0]))\n",
    "                        ET.SubElement(box, \"ymin\").text = str(int(bounding_boxes[1]))\n",
    "                        ET.SubElement(box, \"xmax\").text = str(int(bounding_boxes[2])+int(bounding_boxes[1]))\n",
    "                        ET.SubElement(box, \"ymax\").text = str(int(bounding_boxes[3]))\n",
    "\n",
    "                        tree = ET.ElementTree(root)\n",
    "                        tree.write(os.path.join(dataset_labels_path, os.path.splitext(img_name)[0] + '.xml'))\n",
    "                        #tree.write(os.path.join(filename +\"-labels\", os.path.splitext(img_name)[0] + '.xml'))\n",
    "                        \n",
    "                except RuntimeError :\n",
    "                    with open(\"delete.txt\", \"a\") as myfile:\n",
    "                        myfile.write(img_path+\"\\n\")\n",
    "                \t#print(img_path)\n",
    "\n",
    "                else :\n",
    "                    with open(\"delete.txt\", \"a\") as myfile:\n",
    "                            myfile.write(img_path+\"\\n\")\n",
    "                    #print('no face')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Masked Photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL - Download the mask images into the mask folder if they do not exist already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/cloud-commander/face-mask-detection/master/data/mask_photos.tar.xz\n",
    "#!mkdir -p training_demo\n",
    "!tar -xf mask_photos.tar.xz -C training_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/masked/10.jpg', 'dataset/masked/7.jpg', 'dataset/masked/12.jpg', 'dataset/masked/11.jpg', 'dataset/masked/9.jpg']\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'dataset/masked'\n",
    "mask_folder = 'training_demo/mask'\n",
    "model = \"hog\" # Select facial recognition model; Available options areh 'hog' or 'cnn'. Hog is faster, cnn is more accurate.\n",
    "\n",
    "num_generated_files = 0\n",
    "input_folder_list = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
    "mask_folder_list = [os.path.join(mask_folder, f) for f in os.listdir(mask_folder) if os.path.isfile(os.path.join(mask_folder, f))]\n",
    "\n",
    "print(input_folder_list)\n",
    "\n",
    "input_folder_path = os.path.join(os.getcwd(), input_folder)\n",
    "mask_folder_path = os.path.join(os.getcwd(), mask_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper code to place masks on the faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(face_image_file, current_image_file):\n",
    "    face_image_file.save(current_image_file)\n",
    "    print(f'Save to {current_image_file}')\n",
    "    \n",
    "\n",
    "def create_mask(current_image_file, current_mask_file, model):\n",
    "    show = False\n",
    "\n",
    "    KEY_FACIAL_FEATURES = ('nose_bridge', 'chin')\n",
    "    face_image_file: ImageFile = None\n",
    "    mask_image_file: ImageFile = None\n",
    "\n",
    "    face_image_np = face_recognition.load_image_file(current_image_file)\n",
    "    face_locations = face_recognition.face_locations(\n",
    "        face_image_np, model=model)\n",
    "    face_landmarks = face_recognition.face_landmarks(\n",
    "        face_image_np, face_locations)\n",
    "    face_image_file = Image.fromarray(face_image_np)\n",
    "    mask_image_file = Image.open(current_mask_file)\n",
    "\n",
    "    found_face = False\n",
    "    for face_landmark in face_landmarks:\n",
    "\n",
    "        # check whether facial features meet requirement\n",
    "        skip = False\n",
    "        for facial_feature in KEY_FACIAL_FEATURES:\n",
    "            if facial_feature not in face_landmark:\n",
    "                skip = True\n",
    "                break\n",
    "            if skip:\n",
    "                continue\n",
    "\n",
    "            # mask face\n",
    "            found_face = True\n",
    "            place_mask(face_landmark, mask_image_file, face_image_file)\n",
    "\n",
    "    if found_face:\n",
    "        if show:\n",
    "            face_image_file.show()\n",
    "\n",
    "        # save\n",
    "        save(face_image_file,current_image_file)\n",
    "    else:\n",
    "        print('Found no face.')\n",
    "\n",
    "\n",
    "def place_mask(face_landmark: dict, mask_image_file, face_image_file):\n",
    "    nose_bridge = face_landmark['nose_bridge']\n",
    "    nose_point = nose_bridge[len(nose_bridge) * 1 // 4]\n",
    "    nose_v = np.array(nose_point)\n",
    "\n",
    "    chin = face_landmark['chin']\n",
    "    chin_len = len(chin)\n",
    "    chin_bottom_point = chin[chin_len // 2]\n",
    "    chin_bottom_v = np.array(chin_bottom_point)\n",
    "    chin_left_point = chin[chin_len // 8]\n",
    "    chin_right_point = chin[chin_len * 7 // 8]\n",
    "\n",
    "    # split mask and resize\n",
    "    width = mask_image_file.width\n",
    "    height = mask_image_file.height\n",
    "    width_ratio = 1.2\n",
    "    new_height = int(np.linalg.norm(nose_v - chin_bottom_v))\n",
    "\n",
    "    # left\n",
    "    mask_left_img = mask_image_file.crop((0, 0, width // 2, height))\n",
    "    mask_left_width = get_distance_from_point_to_line(\n",
    "        chin_left_point, nose_point, chin_bottom_point)\n",
    "    mask_left_width = int(mask_left_width * width_ratio)\n",
    "    mask_left_img = mask_left_img.resize((mask_left_width, new_height))\n",
    "\n",
    "    # right\n",
    "    mask_right_img = mask_image_file.crop((width // 2, 0, width, height))\n",
    "    mask_right_width = get_distance_from_point_to_line(\n",
    "        chin_right_point, nose_point, chin_bottom_point)\n",
    "    mask_right_width = int(mask_right_width * width_ratio)\n",
    "    mask_right_img = mask_right_img.resize((mask_right_width, new_height))\n",
    "\n",
    "    # merge mask\n",
    "    size = (mask_left_img.width + mask_right_img.width, new_height)\n",
    "    mask_img = Image.new('RGBA', size)\n",
    "    mask_img.paste(mask_left_img, (0, 0), mask_left_img)\n",
    "    mask_img.paste(mask_right_img, (mask_left_img.width, 0), mask_right_img)\n",
    "\n",
    "    # rotate mask\n",
    "    angle = np.arctan2(\n",
    "        chin_bottom_point[1] - nose_point[1], chin_bottom_point[0] - nose_point[0])\n",
    "    rotatedmask_image_file = mask_img.rotate(angle, expand=True)\n",
    "\n",
    "    # calculate mask location\n",
    "    center_x = (nose_point[0] + chin_bottom_point[0]) // 2\n",
    "    center_y = (nose_point[1] + chin_bottom_point[1]) // 2\n",
    "\n",
    "    offset = mask_img.width // 2 - mask_left_img.width\n",
    "    radian = angle * np.pi / 180\n",
    "    box_x = center_x + int(offset * np.cos(radian)) - \\\n",
    "        rotatedmask_image_file.width // 2\n",
    "    box_y = center_y + int(offset * np.sin(radian)) - \\\n",
    "        rotatedmask_image_file.height // 2\n",
    "\n",
    "    # add mask\n",
    "    face_image_file.paste(mask_img, (box_x, box_y), mask_img)\n",
    "\n",
    "\n",
    "def get_distance_from_point_to_line(point, line_point1, line_point2):\n",
    "    distance = np.abs((line_point2[1] - line_point1[1]) * point[0] +\n",
    "                      (line_point1[0] - line_point2[0]) * point[1] +\n",
    "                      (line_point2[0] - line_point1[0]) * line_point1[1] +\n",
    "                      (line_point1[1] - line_point2[1]) * line_point1[0]) / \\\n",
    "        np.sqrt((line_point2[1] - line_point1[1]) * (line_point2[1] - line_point1[1]) +\n",
    "                (line_point1[0] - line_point2[0]) * (line_point1[0] - line_point2[0]))\n",
    "    return int(distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We loop through all the files in our input directory, place masks on the faces and the save them in the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to /home/jovyan/work/Generate_Data/dataset/masked/10.jpg\n",
      "Save to /home/jovyan/work/Generate_Data/dataset/masked/7.jpg\n",
      "Save to /home/jovyan/work/Generate_Data/dataset/masked/12.jpg\n",
      "Save to /home/jovyan/work/Generate_Data/dataset/masked/11.jpg\n",
      "Save to /home/jovyan/work/Generate_Data/dataset/masked/9.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_folder_list)):\n",
    "    # get a random mask from from the mask folder\n",
    "    random_mask_file = random.choice(list(mask_folder_list))\n",
    "    random_mask_file = os.getcwd() + \"/\" + random_mask_file\n",
    "    \n",
    "    # get the next image from the image folder\n",
    "    current_image_file = os.getcwd() + \"/\" + input_folder_list[i]\n",
    "    create_mask(current_image_file, random_mask_file, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the generated images and archive them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels_folder = input_folder_path + \"-labels\"\n",
    "source1 = input_folder_path + \"/\"\n",
    "source2 = dataset_labels_folder  + \"/\"\n",
    "\n",
    "destination = os.getcwd() + \"/training_demo\"+ \"/images\"\n",
    "\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "\n",
    "\n",
    "def move_files(source,destination):\n",
    "    files = os.listdir(source)\n",
    "    for f in files:\n",
    "        shutil.move(source+f, destination)\n",
    "\n",
    "\n",
    "move_files(source1,destination)\n",
    "move_files(source2,destination)\n",
    "\n",
    "# deletes source directories, use as needed\n",
    "os.rmdir(source2)\n",
    "os.rmdir(source1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress Dataset (Optional) ###\n",
    "\n",
    "Follow this step if you wish to archive your dataset for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r dataset.zip dataset\n",
    "#!tar -zcvf dataset.tar.gz dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
