{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"https://blog.cloudcommander.net\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/cloud-commander/hexoblog/master/cloud.png\" alt=\"Visit my Blog\"></a> <span style=\"font-family:Didot; font-size:3em;\"> Cloud Commander </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/cloud-commander/face-mask-detection/blob/master/3_Prepare_Data_Partition_LabelMap_CSVtoXML.ipynb/" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"></a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"https://github.com/cloud-commander/face-mask-detection/blob/master/3_Prepare_Data_Partition_LabelMap_CSVtoXML.ipynb/" target=\"_parent\"><img src=\"https://img.shields.io/static/v1?logo=GitHub&label=&color=333333&style=flat&message=View%20on%20GitHub\" alt=\"View in GitHub\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the images\n",
    "\n",
    "We continue our data preparation by splitting our dataset into training and test sets.\n",
    "\n",
    "Typically, the ratio is 90%/10%, i.e. 90% of the images are used for training and the rest 10% is maintained for testing, but you can chose whatever ratio suits your needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add our dataset into our notebook (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define folder locations and split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imageDir = os.getcwd() + \"/training_demo/images\"\n",
    "outputDir = imageDir \n",
    "ratio = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Generate_Data/training_demo/images/train\n",
      "/home/jovyan/work/Generate_Data/training_demo/images/test\n",
      "1\n",
      "WARNING, the following XML file does not exist:/home/jovyan/work/Generate_Data/training_demo/images/18.xml\n",
      "WARNING, the following XML file does not exist:/home/jovyan/work/Generate_Data/training_demo/images/7.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def iterate_dir(source, dest, ratio):\n",
    "    source = source.replace('\\\\', '/')\n",
    "    dest = dest.replace('\\\\', '/')\n",
    "    train_dir = os.path.join(dest, 'train')\n",
    "    print(train_dir)\n",
    "    test_dir = os.path.join(dest, 'test')\n",
    "    print(test_dir)\n",
    "    \n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    \n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "        \n",
    "    images = [f for f in os.listdir(source)\n",
    "              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(.jpg|.jpeg|.png)$', f)]\n",
    "\n",
    "     \n",
    "    num_images = len(images)\n",
    "    num_test_images = math.ceil(ratio*num_images)\n",
    "    \n",
    "    print(num_test_images)\n",
    "        \n",
    "    for i in range(num_test_images):\n",
    "        idx = random.randint(0, len(images)-1)\n",
    "        \n",
    "        filename = images[idx]\n",
    "        filename_path = os.path.join(source, filename)\n",
    "        \n",
    "        xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "        xml_path = os.path.join(source, xml_filename)\n",
    "        \n",
    "        #copy image + XML files across only if accompanying XML file exists\n",
    "        if os.path.isfile(xml_path):     \n",
    "                copyfile(filename_path, os.path.join(test_dir, filename))\n",
    "                copyfile(xml_path,os.path.join(test_dir,xml_filename))\n",
    "        else:\n",
    "            print(\"WARNING: the following XML file does not exist:\" + xml_path)\n",
    "        images.remove(images[idx])\n",
    "\n",
    "    for filename in images:\n",
    "        xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "        xml_path = os.path.join(source, xml_filename)\n",
    "        filename_path = os.path.join(source, filename)\n",
    "        \n",
    "        #copy image + XML files across only if accompanying XML file exists\n",
    "        if os.path.isfile(xml_path):\n",
    "                copyfile(filename_path, os.path.join(train_dir, filename))\n",
    "                copyfile(xml_path, os.path.join(train_dir, xml_filename))\n",
    "        else:\n",
    "            print(\"WARNING: the following XML file does not exist:\" + xml_path)\n",
    "\n",
    "\n",
    "iterate_dir(imageDir, outputDir, ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Delete original files\n",
    "\n",
    "Once we are happy the images have successfully split into training and test sets, we can go ahead and delete the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'training_demo/images/10.jpg'\r\n",
      "removed 'training_demo/images/10.xml'\r\n",
      "removed 'training_demo/images/11.jpg'\r\n",
      "removed 'training_demo/images/11.xml'\r\n",
      "removed 'training_demo/images/12.jpg'\r\n",
      "removed 'training_demo/images/12.xml'\r\n",
      "removed 'training_demo/images/18.jpg'\r\n",
      "removed 'training_demo/images/2.jpg'\r\n",
      "removed 'training_demo/images/2.xml'\r\n",
      "removed 'training_demo/images/3.jpg'\r\n",
      "removed 'training_demo/images/3.xml'\r\n",
      "removed 'training_demo/images/4.jpg'\r\n",
      "removed 'training_demo/images/4.xml'\r\n",
      "removed 'training_demo/images/6.jpg'\r\n",
      "removed 'training_demo/images/6.xml'\r\n",
      "removed 'training_demo/images/7.jpg'\r\n",
      "removed 'training_demo/images/9.jpg'\r\n",
      "removed 'training_demo/images/9.xml'\r\n",
      "rm: cannot remove 'training_demo/images/test': Is a directory\r\n",
      "rm: cannot remove 'training_demo/images/train': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -v training_demo/images/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Map\n",
    "\n",
    "TensorFlow requires a label map, which namely maps each of the used labels to an integer values. This label map is used both by the training and detection processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-03 17:45:18--  https://raw.githubusercontent.com/cloud-commander/face-mask-detection/master/label_map.pbtxt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 79 [text/plain]\n",
      "Saving to: ‘training_demo/annotations/label_map.pbtxt’\n",
      "\n",
      "label_map.pbtxt     100%[===================>]      79  --.-KB/s    in 0s      \n",
      "\n",
      "2020-06-03 17:45:19 (7.06 MB/s) - ‘training_demo/annotations/label_map.pbtxt’ saved [79/79]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p training_demo/annotations\n",
    "!wget https://raw.githubusercontent.com/cloud-commander/face-mask-detection/master/label_map.pbtxt -P training_demo/annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML to CSV ##\n",
    "\n",
    "And finally we need to generate a CSV file containing all image detail / classes from the individual XML files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define locations for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getcwd() + \"/training_demo\"\n",
    "images_path = dataset_path + \"/images\"\n",
    "annotations_path = dataset_path + \"/annotations\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to generate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    print(\"test1\"+path)\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        print(xml_file)\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            \n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "            \n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "def generate_csv(folder):\n",
    "    xml_path = os.path.join(images_path , folder)\n",
    "    print(xml_path)\n",
    "    xml_df = xml_to_csv(xml_path)\n",
    "    print(xml_df)\n",
    "    xml_df.to_csv(annotations_path + '/' + folder +'_labels.csv', index=None)\n",
    "    csv_path = dataset_path + \"/\" + folder\n",
    "    print('Successfully converted train xml to csv.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate CSV files\n",
    "\n",
    "For the train and test folders and place result in annotations folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv(\"train\")\n",
    "generate_csv(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
